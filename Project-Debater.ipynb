{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Debater\n",
    "\n",
    "[API documentation](https://early-access-program.debater.res.ibm.com/#claim_detection)\n",
    "\n",
    "[Download library here](https://early-access-program.debater.res.ibm.com/download_sdk.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from debater_python_api.api.debater_api import DebaterApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "APIKEY = ''\n",
    "debater_api = DebaterApi(APIKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pro / Con \n",
    "\n",
    "- Given a topic sentence and other sentences, it returns a score from (-1,1) where:\n",
    "    - 1 represents a 'pro' (the other sentence supports the topic)\n",
    "    - 0 represents indifference (the other sentence is unrelated to the topic)\n",
    "    - -1 represents a 'con' (the other sentence rejects the topic)\n",
    "    \n",
    "    \n",
    "Standalone, I don't think it is incredibly useful. However, I see two major potential use cases where we could implement this (and I'm sure there are more).\n",
    "\n",
    "1. Identifying posts for human annotation.\n",
    "\n",
    "Since part of the annotation problem is going to be finding documents/text that is actually relevant in the large dataset, this could be run to get scores for all posts in the dataset. We would then have the annotators start with the highest/lowest scoring posts to ensure we accurately identify all the obvious text. \n",
    "\n",
    "2. Use for automated ground truth \n",
    "\n",
    "As part of an ensemble method, I think this could be built in to ground truth labeling in an automated fashion. It's also possible this could be used to label political affiliation based on mean pro/con score or some other metric.\n",
    "\n",
    "- Concerns\n",
    "    - It is only English language. So everything would have to be translated\n",
    "    - This was trained on very proper English, and we will definitely have to process the data. Unsure how to handle hashtags, @mentions, etc\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ProConClient: 100%|██████████| 3/3 [00:00<00:00, 25.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With respect to topic: \"Social media is harmful\", sentences and their scores are: \n",
      "\n",
      "Sentence : Social media disproportionally promotes fake news\n",
      "Score: 0.9993\n",
      "\n",
      "Sentence : Social media is wonderful for human relationship\n",
      "Score: -0.9991\n",
      "\n",
      "Sentence : The air in Los Angeles is clear\n",
      "Score: -0.1935\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# toy example from IBM\n",
    "\n",
    "pro_con_client = debater_api.get_pro_con_client()\n",
    "\n",
    "topic = 'Social media is harmful'\n",
    "sentences = [\n",
    "    'Social media disproportionally promotes fake news',\n",
    "    'Social media is wonderful for human relationship',\n",
    "    'The air in Los Angeles is clear']\n",
    "\n",
    "sentence_topic_dicts = [{'sentence' : sentence, 'topic' : topic } for sentence in sentences]\n",
    "\n",
    "scores = pro_con_client.run(sentence_topic_dicts)\n",
    "\n",
    "print('With respect to topic: \"'+topic+'\", sentences and their scores are: \\n')\n",
    "for i in range(len(sentences)):\n",
    "    print(\"Sentence : \"+sentences[i])\n",
    "    print(\"Score: \"+\"{:.4f}\".format(scores[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ProConClient: 100%|██████████| 3/3 [00:00<00:00, 12.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With respect to topic: \"President Donald Trump is a great leader\", sentences and their scores are: \n",
      "\n",
      "Sentence : Last night’s Trump Klan rally proves yet again he’s an incredibly demented, sadistic, dangerous, violence-inciting, pathologically-lying corrupt traitor hellbent on destroying our democracy and becoming dictator\n",
      "Score: -0.9653\n",
      "\n",
      "Sentence : Thank you President Trump! It WAS a big night for the campaign and for Arizona - - We have your back all the way!\n",
      "Score: 0.3521\n",
      "\n",
      "Sentence : The air in Los Angeles is clear\n",
      "Score: 0.1587\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# More realistic example\n",
    "\n",
    "pro_con_client = debater_api.get_pro_con_client()\n",
    "\n",
    "topic = 'President Donald Trump is a great leader'\n",
    "sentences = [\n",
    "    'Last night’s Trump Klan rally proves yet again he’s an incredibly demented, sadistic, dangerous, violence-inciting, pathologically-lying corrupt traitor hellbent on destroying our democracy and becoming dictator',\n",
    "    'Thank you President Trump! It WAS a big night for the campaign and for Arizona - - We have your back all the way!',\n",
    "    'The air in Los Angeles is clear']\n",
    "\n",
    "sentence_topic_dicts = [{'sentence' : sentence, 'topic' : topic } for sentence in sentences]\n",
    "\n",
    "scores = pro_con_client.run(sentence_topic_dicts)\n",
    "\n",
    "print('With respect to topic: \"'+topic+'\", sentences and their scores are: \\n')\n",
    "for i in range(len(sentences)):\n",
    "    print(\"Sentence : \"+sentences[i])\n",
    "    print(\"Score: \"+\"{:.4f}\".format(scores[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
